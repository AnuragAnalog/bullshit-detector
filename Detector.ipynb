{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgVuuuj1ritJ"
      },
      "source": [
        "# Fake News Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29gEKtWRr7Ar",
        "outputId": "02390874-952e-4e11-f8bf-23d73ae59ac9"
      },
      "source": [
        "# Download the dataset\n",
        "\n",
        "!wget -O \"liar.zip\" \"https://www.cs.ucsb.edu/~william/data/liar_dataset.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-10 01:13:21--  https://www.cs.ucsb.edu/~william/data/liar_dataset.zip\n",
            "Resolving www.cs.ucsb.edu (www.cs.ucsb.edu)... 23.185.0.3, 2620:12a:8000::3, 2620:12a:8001::3\n",
            "Connecting to www.cs.ucsb.edu (www.cs.ucsb.edu)|23.185.0.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://sites.cs.ucsb.edu/~william/data/liar_dataset.zip [following]\n",
            "--2021-05-10 01:13:21--  https://sites.cs.ucsb.edu/~william/data/liar_dataset.zip\n",
            "Resolving sites.cs.ucsb.edu (sites.cs.ucsb.edu)... 128.111.27.164\n",
            "Connecting to sites.cs.ucsb.edu (sites.cs.ucsb.edu)|128.111.27.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1013571 (990K) [application/zip]\n",
            "Saving to: ‘liar.zip’\n",
            "\n",
            "liar.zip            100%[===================>] 989.82K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-10 01:13:21 (15.0 MB/s) - ‘liar.zip’ saved [1013571/1013571]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgVAFmpNg1QQ",
        "outputId": "85c3da6a-be8f-4fb1-e6d8-51d160916def"
      },
      "source": [
        "# Module downloads\n",
        "\n",
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/21/d13081805e1e1afc71f5bb743ece324c8bd576237c51b899ecb38a717502/optuna-2.7.0-py3-none-any.whl (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 8.8MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/ff/375a0a81965a7ad4e23d1786de218e9bae050c4d3927cc9b2783aa045401/alembic-1.6.2.tar.gz (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/d6/7d9acb68a77acd140be7fececb7f2701b2a29d2da9c54184cb8f93509590/cliff-3.7.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.0MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (3.10.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 29.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/15061b32332bb35ea2a2f6263d0f616779d576e82739ec8e7fcf3c94abf5/cmd2-1.5.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 25.1MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
            "Building wheels for collected packages: alembic, pyperclip\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.6.2-py2.py3-none-any.whl size=164219 sha256=5ec63f77dea5fd295888bce49e3af95318825b5f372e18cd953e1556c4d16d62\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/63/44/db29401e49ef5331c163b591f12a465c40af864bfa888dabd2\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11107 sha256=696e1d923de6c395e77e2f8deb026e05c7d212ea2c2113f19bcdd2cd2803fa5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built alembic pyperclip\n",
            "Installing collected packages: colorlog, Mako, python-editor, alembic, cmaes, pbr, pyperclip, colorama, cmd2, stevedore, cliff, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.6.2 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-5.0.1 optuna-2.7.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW67vyctpz1D"
      },
      "source": [
        "# Required modules\n",
        "\n",
        "import os\n",
        "import nltk\n",
        "import string\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8BqvkSYGvXB",
        "outputId": "86b42d16-47aa-4ee5-cf93-bd1195446b3c"
      },
      "source": [
        "# Package downloads\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJjHh40UspUc"
      },
      "source": [
        "# Initial Configration\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (12, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH-4p__ssfkT"
      },
      "source": [
        "# Extracting the dataset\n",
        "\n",
        "with ZipFile('liar.zip', 'r') as zf:\n",
        "    zf.extractall('./')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTyWL9-bxmM2"
      },
      "source": [
        "# Use this column names\n",
        "\n",
        "columns = ['ID', 'Label', 'Statement', 'Subject', 'Speaker', 'Speaker Job', 'State info', 'Party Affiliation', 'BT', 'F', 'HT', 'MT', 'Pants on fire', 'Context']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "muswtLGRtu5k",
        "outputId": "a71b23be-a4e2-49d3-9f15-f09b345e9493"
      },
      "source": [
        "# Loading the dataset\n",
        "\n",
        "train = pd.read_csv('train.tsv', sep='\\t', header=None, names=columns)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Speaker</th>\n",
              "      <th>Speaker Job</th>\n",
              "      <th>State info</th>\n",
              "      <th>Party Affiliation</th>\n",
              "      <th>BT</th>\n",
              "      <th>F</th>\n",
              "      <th>HT</th>\n",
              "      <th>MT</th>\n",
              "      <th>Pants on fire</th>\n",
              "      <th>Context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2635.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a mailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a floor speech.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>324.json</td>\n",
              "      <td>mostly-true</td>\n",
              "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1123.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Health care reform legislation is likely to ma...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>a news release</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9028.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>The economic turnaround started at the end of ...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>an interview on CNN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID        Label  ... Pants on fire              Context\n",
              "0   2635.json        false  ...           0.0             a mailer\n",
              "1  10540.json    half-true  ...           0.0      a floor speech.\n",
              "2    324.json  mostly-true  ...           9.0               Denver\n",
              "3   1123.json        false  ...          44.0       a news release\n",
              "4   9028.json    half-true  ...           2.0  an interview on CNN\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "mmq73Yr7xpfs",
        "outputId": "8e1168e7-fd01-4041-fc9f-65d93a0d36ca"
      },
      "source": [
        "# Inspecting the data\n",
        "\n",
        "train.info()\n",
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10240 entries, 0 to 10239\n",
            "Data columns (total 14 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   ID                 10240 non-null  object \n",
            " 1   Label              10240 non-null  object \n",
            " 2   Statement          10240 non-null  object \n",
            " 3   Subject            10238 non-null  object \n",
            " 4   Speaker            10238 non-null  object \n",
            " 5   Speaker Job        7343 non-null   object \n",
            " 6   State info         8032 non-null   object \n",
            " 7   Party Affiliation  10238 non-null  object \n",
            " 8   BT                 10238 non-null  float64\n",
            " 9   F                  10238 non-null  float64\n",
            " 10  HT                 10238 non-null  float64\n",
            " 11  MT                 10238 non-null  float64\n",
            " 12  Pants on fire      10238 non-null  float64\n",
            " 13  Context            10138 non-null  object \n",
            "dtypes: float64(5), object(9)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BT</th>\n",
              "      <th>F</th>\n",
              "      <th>HT</th>\n",
              "      <th>MT</th>\n",
              "      <th>Pants on fire</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10238.000000</td>\n",
              "      <td>10238.000000</td>\n",
              "      <td>10238.000000</td>\n",
              "      <td>10238.000000</td>\n",
              "      <td>10238.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>11.533210</td>\n",
              "      <td>13.286482</td>\n",
              "      <td>17.133718</td>\n",
              "      <td>16.434265</td>\n",
              "      <td>6.201407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>18.973764</td>\n",
              "      <td>24.112936</td>\n",
              "      <td>35.846511</td>\n",
              "      <td>36.151688</td>\n",
              "      <td>16.128927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>105.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 BT             F            HT            MT  Pants on fire\n",
              "count  10238.000000  10238.000000  10238.000000  10238.000000   10238.000000\n",
              "mean      11.533210     13.286482     17.133718     16.434265       6.201407\n",
              "std       18.973764     24.112936     35.846511     36.151688      16.128927\n",
              "min        0.000000      0.000000      0.000000      0.000000       0.000000\n",
              "25%        0.000000      0.000000      0.000000      0.000000       0.000000\n",
              "50%        2.000000      2.000000      3.000000      3.000000       1.000000\n",
              "75%       12.000000     12.000000     13.000000     11.000000       5.000000\n",
              "max       70.000000    114.000000    160.000000    163.000000     105.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQbAc_-9n2ME"
      },
      "source": [
        "# Loading the validation data\n",
        "\n",
        "valid = pd.read_csv('valid.tsv', sep='\\t', header=None, names=columns)\n",
        "test = pd.read_csv('test.tsv', sep='\\t', header=None, names=columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC-BGvf7AB59"
      },
      "source": [
        "# Important functions\n",
        "\n",
        "def evaluate_on_data(model, X, y, name, typeof=\"train\"):\n",
        "    model.fit(X, y)\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    y_num = (y == 'Real').astype('uint8')\n",
        "    y_pred_num = (y_pred == 'Real').astype('uint8')\n",
        "\n",
        "    acc = round(accuracy_score(y_pred_num, y_num)*100, 6)\n",
        "    recall = round(recall_score(y_pred_num, y_num)*100, 6)\n",
        "    precision = round(precision_score(y_pred_num, y_num)*100, 6)\n",
        "    f1 = round(f1_score(y_pred_num, y_num)*100, 6)\n",
        "\n",
        "    border = \"+\"+\"-\"*39+\"+\"\n",
        "    title = \"|\"+\"\".join(name+\"(\"+typeof+\")\").center(39)+\"|\"\n",
        "    subtitle = \"|\"+\"|\".join([' Accuracy', '    F1   ', '  Recall ', 'Precision'])+\"|\"\n",
        "    vals = \"|\"+\"|\".join(map(str, [acc, f1, recall, precision]))+\"|\"\n",
        "\n",
        "    print(\"\\n\".join([border,title,border,subtitle,border,vals,border,\"\"]))\n",
        "\n",
        "    return"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otz7vTeq5g7i"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlGtM9M65jIS"
      },
      "source": [
        "# Applying some preprocessing\n",
        "\n",
        "train['Subject'] = train['Subject'].replace(np.nan, \"\")\n",
        "train['Speaker'] = train['Speaker'].replace(np.nan, \"\")\n",
        "train['Speaker Job'] = train['Speaker Job'].replace(np.nan, \"\")\n",
        "train['State info'] = train['State info'].replace(np.nan, \"\")\n",
        "train['Party Affiliation'] = train['Party Affiliation'].replace(np.nan, \"\")\n",
        "\n",
        "valid['Subject'] = valid['Subject'].replace(np.nan, \"\")\n",
        "valid['Speaker'] = valid['Speaker'].replace(np.nan, \"\")\n",
        "valid['Speaker Job'] = valid['Speaker Job'].replace(np.nan, \"\")\n",
        "valid['State info'] = valid['State info'].replace(np.nan, \"\")\n",
        "valid['Party Affiliation'] = valid['Party Affiliation'].replace(np.nan, \"\")\n",
        "\n",
        "test['Subject'] = test['Subject'].replace(np.nan, \"\")\n",
        "test['Speaker'] = test['Speaker'].replace(np.nan, \"\")\n",
        "test['Speaker Job'] = test['Speaker Job'].replace(np.nan, \"\")\n",
        "test['State info'] = test['State info'].replace(np.nan, \"\")\n",
        "test['Party Affiliation'] = test['Party Affiliation'].replace(np.nan, \"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8o1sH7DHgrD"
      },
      "source": [
        "# Important preporcessing functions\n",
        "\n",
        "def remove_punctuation(text, puncts):\n",
        "    return \"\".join([c for c in text if c not in puncts])\n",
        "\n",
        "def remove_stopwords(text, stopwords):\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    return \" \".join([tok for tok in tokens if tok not in stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgll4rcLIXQu"
      },
      "source": [
        "stems = PorterStemmer()\n",
        "\n",
        "MAPPER = {'pants-fire': 'Fake', 'false': 'Fake', 'barely-true': 'Fake', 'half-true': 'Real', 'mostly-true': 'Real', 'true': 'Real'}\n",
        "english_sw = stopwords.words('english')\n",
        "punctuations = string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRj170AXeu0C"
      },
      "source": [
        "# Preprocessing features\n",
        "\n",
        "train['preprocessed'] = train['Statement'].apply(lambda x: remove_stopwords(x, english_sw))\n",
        "train['preprocessed'] = train['preprocessed'].apply(lambda x: remove_punctuation(x, punctuations))\n",
        "train['preprocessed'] = train['preprocessed'].apply(lambda x: stems.stem(x))\n",
        "\n",
        "valid['preprocessed'] = valid['Statement'].apply(lambda x: remove_stopwords(x, english_sw))\n",
        "valid['preprocessed'] = valid['preprocessed'].apply(lambda x: remove_punctuation(x, punctuations))\n",
        "valid['preprocessed'] = valid['preprocessed'].apply(lambda x: stems.stem(x))\n",
        "\n",
        "test['preprocessed'] = test['Statement'].apply(lambda x: remove_stopwords(x, english_sw))\n",
        "test['preprocessed'] = test['preprocessed'].apply(lambda x: remove_punctuation(x, punctuations))\n",
        "test['preprocessed'] = test['preprocessed'].apply(lambda x: stems.stem(x))\n",
        "\n",
        "train['Label_mapped'] = train['Label'].apply(lambda x: MAPPER[x])\n",
        "valid['Label_mapped'] = valid['Label'].apply(lambda x: MAPPER[x])\n",
        "test['Label_mapped'] = test['Label'].apply(lambda x: MAPPER[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZw4gkm2DbYE"
      },
      "source": [
        "# Separating out features and labels\n",
        "\n",
        "X_train = train['preprocessed']\n",
        "y_train = train['Label_mapped']\n",
        "\n",
        "X_valid = valid['preprocessed']\n",
        "y_valid = valid['Label_mapped']\n",
        "\n",
        "X_test = test['preprocessed']\n",
        "y_test = test['Label_mapped']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e442KjvqLwQ"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDk0cujLsDsw"
      },
      "source": [
        "### Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kkd3zPHDgaS",
        "outputId": "161aad93-0d56-4fc7-ec53-53714028d814"
      },
      "source": [
        "# Creating a count vectorizer\n",
        "\n",
        "count_vec = CountVectorizer()\n",
        "count_vec.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ2S8cbmFl11"
      },
      "source": [
        "# Getting the train and valid vectors\n",
        "\n",
        "count_train = count_vec.transform(X_train)\n",
        "count_valid = count_vec.transform(X_valid)\n",
        "count_test = count_vec.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXoTsufigcFq"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOIHoR5Igz0Z"
      },
      "source": [
        "# Parameter grid\n",
        "\n",
        "def objective(trial):\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
        "    C = trial.suggest_loguniform('C', 10e-6, 1)\n",
        "\n",
        "    params = {'penalty': penalty, 'C': C}\n",
        "\n",
        "    clf = LogisticRegression(**params)\n",
        "\n",
        "    return cross_val_score(clf, count_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2cM0fkWkTqj",
        "outputId": "af5261cd-4bf8-44ac-e93c-941f184d8a37"
      },
      "source": [
        "# Logistic Regression fitting\n",
        "\n",
        "study = optuna.create_study(study_name='count_logreg', direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 01:13:38,112]\u001b[0m A new study created in memory with name: count_logreg\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 01:13:39,436]\u001b[0m Trial 0 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 01:13:39,529]\u001b[0m Trial 1 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 01:13:39,609]\u001b[0m Trial 2 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:42,199]\u001b[0m Trial 3 finished with value: 0.55 and parameters: {'penalty': 'none', 'C': 0.730611950296751}. Best is trial 3 with value: 0.55.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 01:13:42,290]\u001b[0m Trial 4 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 01:13:42,376]\u001b[0m Trial 5 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 01:13:42,457]\u001b[0m Trial 6 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 01:13:42,543]\u001b[0m Trial 7 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 01:13:42,629]\u001b[0m Trial 8 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:45,245]\u001b[0m Trial 9 finished with value: 0.55 and parameters: {'penalty': 'none', 'C': 1.1952946693053484e-05}. Best is trial 3 with value: 0.55.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5N0mzj5ki07",
        "outputId": "368c4e0e-1330-4cc8-e28e-32ae0d4dc0d9"
      },
      "source": [
        "# Best trial\n",
        "\n",
        "logreg_trial = study.best_trial\n",
        "\n",
        "best_logreg = LogisticRegression(**logreg_trial.params)\n",
        "best_logreg.fit(count_train, y_train)\n",
        "(best_logreg.predict(count_train) == y_train).mean(), (best_logreg.predict(count_valid) == y_valid).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
            "\n",
            "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.999609375, 0.5654205607476636)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWUgpYgkHUNF",
        "outputId": "f4a770b7-b40d-4d81-86a1-61c2fb37d79c"
      },
      "source": [
        "# logreg evaluation\n",
        "\n",
        "evaluate_on_data(LogisticRegression(**logreg_trial.params), count_train, y_train, \"Logistic Regression Count\")\n",
        "evaluate_on_data(LogisticRegression(**logreg_trial.params), count_valid, y_valid, \"Logistic Regression Count\", \"valid\")\n",
        "evaluate_on_data(LogisticRegression(**logreg_trial.params), count_test, y_test, \"Logistic Regression Count\", \"test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
            "\n",
            "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
            "\n",
            "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|    Logistic Regression Count(train)   |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|99.960938|99.965236|99.947862|99.982615|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|    Logistic Regression Count(valid)   |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|100.0|100.0|100.0|100.0|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|    Logistic Regression Count(test)    |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|100.0|100.0|100.0|100.0|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
            "\n",
            "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpOpiZ2wFKqz"
      },
      "source": [
        "### Multinomail Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keTwaV0ZFVBE"
      },
      "source": [
        "# Parametr grid\n",
        "\n",
        "def objective(trial):\n",
        "    alpha = trial.suggest_int('alpha', 1.0, 8.0)\n",
        "\n",
        "    clf = MultinomialNB(alpha=alpha)\n",
        "\n",
        "    return cross_val_score(clf, count_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRHUWdd8Fza-",
        "outputId": "c7e4c302-fb77-4a8c-acae-d8815dc2d16b"
      },
      "source": [
        "# Multinomail navie bayes fitting\n",
        "\n",
        "study = optuna.create_study(study_name='count_nb', direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 01:13:47,131]\u001b[0m A new study created in memory with name: count_nb\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:47,519]\u001b[0m Trial 0 finished with value: 0.60615234375 and parameters: {'alpha': 1}. Best is trial 0 with value: 0.60615234375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:47,851]\u001b[0m Trial 1 finished with value: 0.60927734375 and parameters: {'alpha': 5}. Best is trial 1 with value: 0.60927734375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:48,191]\u001b[0m Trial 2 finished with value: 0.60654296875 and parameters: {'alpha': 8}. Best is trial 1 with value: 0.60927734375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:48,520]\u001b[0m Trial 3 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 3 with value: 0.6095703125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:48,865]\u001b[0m Trial 4 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 3 with value: 0.6095703125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:49,203]\u001b[0m Trial 5 finished with value: 0.6064453125 and parameters: {'alpha': 7}. Best is trial 3 with value: 0.6095703125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:49,536]\u001b[0m Trial 6 finished with value: 0.60654296875 and parameters: {'alpha': 8}. Best is trial 3 with value: 0.6095703125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:49,873]\u001b[0m Trial 7 finished with value: 0.60791015625 and parameters: {'alpha': 6}. Best is trial 3 with value: 0.6095703125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:50,203]\u001b[0m Trial 8 finished with value: 0.60615234375 and parameters: {'alpha': 1}. Best is trial 3 with value: 0.6095703125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:50,531]\u001b[0m Trial 9 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 3 with value: 0.6095703125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:50,887]\u001b[0m Trial 10 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:51,219]\u001b[0m Trial 11 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:51,571]\u001b[0m Trial 12 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:51,907]\u001b[0m Trial 13 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:52,253]\u001b[0m Trial 14 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:52,582]\u001b[0m Trial 15 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:52,922]\u001b[0m Trial 16 finished with value: 0.60927734375 and parameters: {'alpha': 5}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:53,255]\u001b[0m Trial 17 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:53,582]\u001b[0m Trial 18 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:53,925]\u001b[0m Trial 19 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:54,257]\u001b[0m Trial 20 finished with value: 0.60791015625 and parameters: {'alpha': 6}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:54,605]\u001b[0m Trial 21 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:54,939]\u001b[0m Trial 22 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:55,274]\u001b[0m Trial 23 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:55,606]\u001b[0m Trial 24 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:55,949]\u001b[0m Trial 25 finished with value: 0.60615234375 and parameters: {'alpha': 1}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:56,281]\u001b[0m Trial 26 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:56,604]\u001b[0m Trial 27 finished with value: 0.60927734375 and parameters: {'alpha': 5}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:56,951]\u001b[0m Trial 28 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:57,275]\u001b[0m Trial 29 finished with value: 0.60615234375 and parameters: {'alpha': 1}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:57,618]\u001b[0m Trial 30 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:57,950]\u001b[0m Trial 31 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:58,284]\u001b[0m Trial 32 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:58,625]\u001b[0m Trial 33 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:58,943]\u001b[0m Trial 34 finished with value: 0.60927734375 and parameters: {'alpha': 5}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:59,256]\u001b[0m Trial 35 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:59,584]\u001b[0m Trial 36 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:13:59,933]\u001b[0m Trial 37 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:00,250]\u001b[0m Trial 38 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:00,575]\u001b[0m Trial 39 finished with value: 0.60615234375 and parameters: {'alpha': 1}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:00,909]\u001b[0m Trial 40 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:01,238]\u001b[0m Trial 41 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:01,564]\u001b[0m Trial 42 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:01,925]\u001b[0m Trial 43 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:02,245]\u001b[0m Trial 44 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:02,582]\u001b[0m Trial 45 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:02,915]\u001b[0m Trial 46 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:03,258]\u001b[0m Trial 47 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:03,589]\u001b[0m Trial 48 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:03,925]\u001b[0m Trial 49 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:04,253]\u001b[0m Trial 50 finished with value: 0.60791015625 and parameters: {'alpha': 6}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:04,584]\u001b[0m Trial 51 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:04,914]\u001b[0m Trial 52 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:05,243]\u001b[0m Trial 53 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:05,567]\u001b[0m Trial 54 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:05,898]\u001b[0m Trial 55 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:06,228]\u001b[0m Trial 56 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:06,544]\u001b[0m Trial 57 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:06,870]\u001b[0m Trial 58 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:07,200]\u001b[0m Trial 59 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:07,522]\u001b[0m Trial 60 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:07,852]\u001b[0m Trial 61 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:08,183]\u001b[0m Trial 62 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:08,519]\u001b[0m Trial 63 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:08,845]\u001b[0m Trial 64 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:09,183]\u001b[0m Trial 65 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:09,532]\u001b[0m Trial 66 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:09,857]\u001b[0m Trial 67 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:10,188]\u001b[0m Trial 68 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:10,519]\u001b[0m Trial 69 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:10,851]\u001b[0m Trial 70 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:11,196]\u001b[0m Trial 71 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:11,523]\u001b[0m Trial 72 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:11,850]\u001b[0m Trial 73 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:12,193]\u001b[0m Trial 74 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:12,524]\u001b[0m Trial 75 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:12,854]\u001b[0m Trial 76 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:13,190]\u001b[0m Trial 77 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:13,520]\u001b[0m Trial 78 finished with value: 0.60927734375 and parameters: {'alpha': 5}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:13,872]\u001b[0m Trial 79 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:14,199]\u001b[0m Trial 80 finished with value: 0.6064453125 and parameters: {'alpha': 7}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:14,525]\u001b[0m Trial 81 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:14,864]\u001b[0m Trial 82 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:15,201]\u001b[0m Trial 83 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:15,540]\u001b[0m Trial 84 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:15,866]\u001b[0m Trial 85 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:16,201]\u001b[0m Trial 86 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:16,525]\u001b[0m Trial 87 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:16,852]\u001b[0m Trial 88 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:17,181]\u001b[0m Trial 89 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:17,509]\u001b[0m Trial 90 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:17,834]\u001b[0m Trial 91 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:18,172]\u001b[0m Trial 92 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:18,497]\u001b[0m Trial 93 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:18,821]\u001b[0m Trial 94 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:19,139]\u001b[0m Trial 95 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:19,466]\u001b[0m Trial 96 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:19,789]\u001b[0m Trial 97 finished with value: 0.61220703125 and parameters: {'alpha': 4}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:20,112]\u001b[0m Trial 98 finished with value: 0.6125 and parameters: {'alpha': 3}. Best is trial 10 with value: 0.6125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:14:20,449]\u001b[0m Trial 99 finished with value: 0.6095703125 and parameters: {'alpha': 2}. Best is trial 10 with value: 0.6125.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HGtLIsDXaTS",
        "outputId": "acb63465-cb7d-46a7-c38c-ff3ac59de824"
      },
      "source": [
        "# Best params\n",
        "\n",
        "nb_trial = study.best_trial\n",
        "\n",
        "nb_best = MultinomialNB(**nb_trial.params)\n",
        "nb_best.fit(count_train, y_train)\n",
        "(nb_best.predict(count_train) == y_train).mean(), (nb_best.predict(count_valid) == y_valid).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.77001953125, 0.6043613707165109)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuBjdnY2HUPP",
        "outputId": "8a248e7f-cbcd-433f-8a71-737d8c88614d"
      },
      "source": [
        "# nb evaluation\n",
        "\n",
        "evaluate_on_data(MultinomialNB(**nb_trial.params), count_train, y_train, \"Multinomial NB Count\")\n",
        "evaluate_on_data(MultinomialNB(**nb_trial.params), count_valid, y_valid, \"Multinomial NB Count\", \"valid\")\n",
        "evaluate_on_data(MultinomialNB(**nb_trial.params), count_test, y_test, \"Multinomial NB Count\", \"test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|      Multinomial NB Count(train)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|77.001953|81.548225|74.226216|90.472879|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|      Multinomial NB Count(valid)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|87.227414|88.335704|84.146341|92.964072|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|       Multinomial NB Count(test)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|82.004736|86.181818|75.961538|99.579832|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLrjtBuAjmMg"
      },
      "source": [
        "### Support vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsRaXzeujr3e"
      },
      "source": [
        "# Parameter grid\n",
        "\n",
        "def objective(trial):\n",
        "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "    if kernel is 'poly':\n",
        "        degree = trial.suggest_int('degree', 1, 4)\n",
        "        gamma = trial.suggest_categorical('gamma', ['scale','auto'])\n",
        "        clf = SVC(kernel=kernel, degree=degree, gamma=gamma)\n",
        "\n",
        "    if kernel in ['rbf', 'sigmoid']:\n",
        "        gamma = trial.suggest_categorical('gamma', ['scale','auto'])\n",
        "        clf = SVC(kernel=kernel, gamma=gamma)\n",
        "\n",
        "    clf = SVC(kernel=kernel)\n",
        "\n",
        "    return cross_val_score(clf, count_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMN8pi4Ch4eX",
        "outputId": "1f041c4d-7967-4c48-aa43-0be8706c2abd"
      },
      "source": [
        "# Support Vector Machines fitting\n",
        "\n",
        "study = optuna.create_study(study_name='count_svc', direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 01:14:20,599]\u001b[0m A new study created in memory with name: count_svc\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:16:00,338]\u001b[0m Trial 0 finished with value: 0.573046875 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'auto'}. Best is trial 0 with value: 0.573046875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:17:25,902]\u001b[0m Trial 1 finished with value: 0.60732421875 and parameters: {'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.60732421875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning:\n",
            "\n",
            "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "\n",
            "\u001b[32m[I 2021-05-10 01:20:47,323]\u001b[0m Trial 2 finished with value: 0.570703125 and parameters: {'kernel': 'linear'}. Best is trial 1 with value: 0.60732421875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:22:27,852]\u001b[0m Trial 3 finished with value: 0.573046875 and parameters: {'kernel': 'poly', 'degree': 1, 'gamma': 'auto'}. Best is trial 1 with value: 0.60732421875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:25:53,001]\u001b[0m Trial 4 finished with value: 0.570703125 and parameters: {'kernel': 'linear'}. Best is trial 1 with value: 0.60732421875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:27:35,746]\u001b[0m Trial 5 finished with value: 0.573046875 and parameters: {'kernel': 'poly', 'degree': 1, 'gamma': 'auto'}. Best is trial 1 with value: 0.60732421875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:29:06,272]\u001b[0m Trial 6 finished with value: 0.60732421875 and parameters: {'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.60732421875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:30:55,332]\u001b[0m Trial 7 finished with value: 0.61474609375 and parameters: {'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.61474609375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:34:24,617]\u001b[0m Trial 8 finished with value: 0.570703125 and parameters: {'kernel': 'linear'}. Best is trial 7 with value: 0.61474609375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:36:08,851]\u001b[0m Trial 9 finished with value: 0.573046875 and parameters: {'kernel': 'poly', 'degree': 4, 'gamma': 'scale'}. Best is trial 7 with value: 0.61474609375.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bztky2Bqjr5g",
        "outputId": "68641e9b-bedd-43dc-e618-72298929c57b"
      },
      "source": [
        "# Best params\n",
        "\n",
        "svc_trial = study.best_trial\n",
        "\n",
        "svc_best = SVC(**svc_trial.params)\n",
        "svc_best.fit(count_train, y_train)\n",
        "(svc_best.predict(count_train) == y_train).mean(), (svc_best.predict(count_valid) == y_valid).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.56171875, 0.5202492211838006)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SI3Qb-8HURb",
        "outputId": "963980a8-e1bc-4269-99b6-f71b91437242"
      },
      "source": [
        "# svc evaluation\n",
        "\n",
        "evaluate_on_data(SVC(**svc_trial.params, probability=True), count_train, y_train, \"SVC Count\")\n",
        "evaluate_on_data(SVC(**svc_trial.params, probability=True), count_valid, y_valid, \"SVC Count\", \"valid\")\n",
        "evaluate_on_data(SVC(**svc_trial.params, probability=True), count_test, y_test, \"SVC Count\", \"test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|            SVC Count(train)           |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|56.171875|71.935968|56.171875|100.0|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|            SVC Count(valid)           |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|52.024922|68.442623|52.024922|100.0|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|            SVC Count(test)            |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|56.353591|72.084806|56.353591|100.0|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R7SEJHXxvQp"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBYXq41E1NDN"
      },
      "source": [
        "# Parameters grid\n",
        "\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 1000, 100)\n",
        "    # criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
        "    max_depth = trial.suggest_categorical('max_depth', [4, 5, 6, None])\n",
        "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2', None])\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
        "\n",
        "    return cross_val_score(clf, count_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Zwwy6B1NzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc44402-5922-41ba-d1f7-6648685414a7"
      },
      "source": [
        "# Random Forest fitting\n",
        "\n",
        "study = optuna.create_study(study_name='count_rf', direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 01:38:10,879]\u001b[0m A new study created in memory with name: count_rf\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:39:04,854]\u001b[0m Trial 0 finished with value: 0.56171875 and parameters: {'n_estimators': 900, 'max_depth': 6, 'max_features': 'auto'}. Best is trial 0 with value: 0.56171875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:40:05,358]\u001b[0m Trial 1 finished with value: 0.56171875 and parameters: {'n_estimators': 1000, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.56171875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:40:19,348]\u001b[0m Trial 2 finished with value: 0.56171875 and parameters: {'n_estimators': 300, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.56171875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:40:40,241]\u001b[0m Trial 3 finished with value: 0.56171875 and parameters: {'n_estimators': 800, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 0 with value: 0.56171875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:40:48,113]\u001b[0m Trial 4 finished with value: 0.56171875 and parameters: {'n_estimators': 300, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 0 with value: 0.56171875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:43:23,861]\u001b[0m Trial 5 finished with value: 0.57626953125 and parameters: {'n_estimators': 200, 'max_depth': 6, 'max_features': None}. Best is trial 5 with value: 0.57626953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:44:12,191]\u001b[0m Trial 6 finished with value: 0.56171875 and parameters: {'n_estimators': 800, 'max_depth': 6, 'max_features': 'auto'}. Best is trial 5 with value: 0.57626953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:45:00,436]\u001b[0m Trial 7 finished with value: 0.56171875 and parameters: {'n_estimators': 900, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 5 with value: 0.57626953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:53:44,516]\u001b[0m Trial 8 finished with value: 0.57177734375 and parameters: {'n_estimators': 800, 'max_depth': 4, 'max_features': None}. Best is trial 5 with value: 0.57626953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 01:58:57,274]\u001b[0m Trial 9 finished with value: 0.57783203125 and parameters: {'n_estimators': 400, 'max_depth': 6, 'max_features': None}. Best is trial 9 with value: 0.57783203125.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsrvjX_mxb-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00563a7-e035-4cb4-cf1d-8146769a6350"
      },
      "source": [
        "# Best params\n",
        "\n",
        "rf_trial = study.best_trial\n",
        "\n",
        "rf_best = RandomForestClassifier(**rf_trial.params)\n",
        "rf_best.fit(count_train, y_train)\n",
        "(rf_best.predict(count_train) == y_train).mean(), (rf_best.predict(count_valid) == y_valid).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.59853515625, 0.5568535825545171)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAaiGiXlHUgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53783ff4-3b59-4cfe-f1c4-04dc7b432f38"
      },
      "source": [
        "# rf evaluation\n",
        "\n",
        "evaluate_on_data(RandomForestClassifier(**rf_trial.params), count_train, y_train, \"Random Forest Count\")\n",
        "evaluate_on_data(RandomForestClassifier(**rf_trial.params), count_valid, y_valid, \"Random Forest Count\", \"valid\")\n",
        "evaluate_on_data(RandomForestClassifier(**rf_trial.params), count_test, y_test, \"Random Forest Count\", \"test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|       Random Forest Count(train)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|59.853516|72.70796|58.812158|95.201669|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|       Random Forest Count(valid)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|65.88785|74.08284|61.252446|93.712575|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|       Random Forest Count(test)       |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|63.456985|75.5156|60.662702|100.0|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wpg-76x2Cvj"
      },
      "source": [
        "### Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaFX0p-I2Gpl"
      },
      "source": [
        "# Parameters grid\n",
        "\n",
        "def objective(trial):\n",
        "    loss = trial.suggest_categorical('loss', ['log', 'modified_huber', 'perceptron'])\n",
        "    penalty = trial.suggest_categorical('penalty', ['l2', 'l1', 'elasticnet'])\n",
        "    max_iter = trial.suggest_int('max_iter', 1000, 2000, 100)\n",
        "    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'optimal', 'invscaling', 'adaptive'])\n",
        "    if learning_rate is not 'optimal':\n",
        "        eta0 = trial.suggest_loguniform('eta0', 10e-6, 1)\n",
        "    else:\n",
        "        eta0 = 0\n",
        "\n",
        "    clf = SGDClassifier(loss=loss, penalty=penalty, learning_rate=learning_rate, eta0=eta0, max_iter=max_iter)\n",
        "\n",
        "    return cross_val_score(clf, count_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXg1qACW2Grb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8e2d76-ea1d-4cf8-c10d-02f5faa99b6f"
      },
      "source": [
        "# SGD fitting\n",
        "\n",
        "study = optuna.create_study(study_name='count_sgd', direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 02:03:46,965]\u001b[0m A new study created in memory with name: count_sgd\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:03:47,234]\u001b[0m Trial 0 finished with value: 0.546875 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.017522383951114166}. Best is trial 0 with value: 0.546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:03:48,499]\u001b[0m Trial 1 finished with value: 0.566796875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1800, 'learning_rate': 'adaptive', 'eta0': 0.007076240735436297}. Best is trial 1 with value: 0.566796875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:03:49,081]\u001b[0m Trial 2 finished with value: 0.58447265625 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1800, 'learning_rate': 'optimal'}. Best is trial 2 with value: 0.58447265625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:03:49,762]\u001b[0m Trial 3 finished with value: 0.6078125 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1200, 'learning_rate': 'invscaling', 'eta0': 0.36959498697581417}. Best is trial 3 with value: 0.6078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:03:50,270]\u001b[0m Trial 4 finished with value: 0.58818359375 and parameters: {'loss': 'modified_huber', 'penalty': 'l1', 'max_iter': 1700, 'learning_rate': 'invscaling', 'eta0': 0.0016867365664614488}. Best is trial 3 with value: 0.6078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:03:52,567]\u001b[0m Trial 5 finished with value: 0.569921875 and parameters: {'loss': 'modified_huber', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.0027899561861697356}. Best is trial 3 with value: 0.6078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:03:53,283]\u001b[0m Trial 6 finished with value: 0.58212890625 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 2000, 'learning_rate': 'optimal'}. Best is trial 3 with value: 0.6078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:03:56,013]\u001b[0m Trial 7 finished with value: 0.57919921875 and parameters: {'loss': 'modified_huber', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.0009563510430882734}. Best is trial 3 with value: 0.6078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:03:56,745]\u001b[0m Trial 8 finished with value: 0.58818359375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1400, 'learning_rate': 'optimal'}. Best is trial 3 with value: 0.6078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:00,457]\u001b[0m Trial 9 finished with value: 0.55029296875 and parameters: {'loss': 'modified_huber', 'penalty': 'l1', 'max_iter': 1000, 'learning_rate': 'optimal'}. Best is trial 3 with value: 0.6078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:01,246]\u001b[0m Trial 10 finished with value: 0.60810546875 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1100, 'learning_rate': 'invscaling', 'eta0': 0.7703344810237969}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:01,925]\u001b[0m Trial 11 finished with value: 0.6076171875 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1100, 'learning_rate': 'invscaling', 'eta0': 0.36163063710549676}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:02,696]\u001b[0m Trial 12 finished with value: 0.6076171875 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1200, 'learning_rate': 'invscaling', 'eta0': 0.729884024525998}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:03,028]\u001b[0m Trial 13 finished with value: 0.5470703125 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'max_iter': 1300, 'learning_rate': 'invscaling', 'eta0': 0.15729682454983435}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:03,361]\u001b[0m Trial 14 finished with value: 0.5783203125 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 4.7825350509926954e-05}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:05,335]\u001b[0m Trial 15 finished with value: 0.58876953125 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1300, 'learning_rate': 'adaptive', 'eta0': 0.08506174313822645}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:05,845]\u001b[0m Trial 16 finished with value: 0.5982421875 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1100, 'learning_rate': 'invscaling', 'eta0': 0.053819898089366304}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:06,234]\u001b[0m Trial 17 finished with value: 0.54970703125 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.8644385937906672}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:06,565]\u001b[0m Trial 18 finished with value: 0.5763671875 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 1.3901772014805727e-05}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:07,579]\u001b[0m Trial 19 finished with value: 0.59990234375 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1200, 'learning_rate': 'adaptive', 'eta0': 0.00020974008174202234}. Best is trial 10 with value: 0.60810546875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:08,722]\u001b[0m Trial 20 finished with value: 0.6091796875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.8442335072518534}. Best is trial 20 with value: 0.6091796875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:09,913]\u001b[0m Trial 21 finished with value: 0.60966796875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.996832111960702}. Best is trial 21 with value: 0.60966796875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:10,979]\u001b[0m Trial 22 finished with value: 0.61044921875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.6097169948292244}. Best is trial 22 with value: 0.61044921875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:11,493]\u001b[0m Trial 23 finished with value: 0.59111328125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.02748586125003281}. Best is trial 22 with value: 0.61044921875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:12,245]\u001b[0m Trial 24 finished with value: 0.609765625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.18896460458163766}. Best is trial 22 with value: 0.61044921875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:13,049]\u001b[0m Trial 25 finished with value: 0.61142578125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1100, 'learning_rate': 'invscaling', 'eta0': 0.2443862484107297}. Best is trial 25 with value: 0.61142578125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:13,405]\u001b[0m Trial 26 finished with value: 0.5580078125 and parameters: {'loss': 'perceptron', 'penalty': 'elasticnet', 'max_iter': 1100, 'learning_rate': 'invscaling', 'eta0': 0.18026351810480679}. Best is trial 25 with value: 0.61142578125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:13,852]\u001b[0m Trial 27 finished with value: 0.58671875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1300, 'learning_rate': 'invscaling', 'eta0': 0.013967057803633703}. Best is trial 25 with value: 0.61142578125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:14,421]\u001b[0m Trial 28 finished with value: 0.60029296875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1100, 'learning_rate': 'invscaling', 'eta0': 0.05899582053287785}. Best is trial 25 with value: 0.61142578125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:15,043]\u001b[0m Trial 29 finished with value: 0.54609375 and parameters: {'loss': 'perceptron', 'penalty': 'elasticnet', 'max_iter': 1400, 'learning_rate': 'constant', 'eta0': 0.16478908591960853}. Best is trial 25 with value: 0.61142578125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:16,793]\u001b[0m Trial 30 finished with value: 0.588671875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1200, 'learning_rate': 'adaptive', 'eta0': 0.33765047556425964}. Best is trial 25 with value: 0.61142578125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:17,955]\u001b[0m Trial 31 finished with value: 0.6099609375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.9195415867913043}. Best is trial 25 with value: 0.61142578125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:18,856]\u001b[0m Trial 32 finished with value: 0.61083984375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.34709710516741943}. Best is trial 25 with value: 0.61142578125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:19,649]\u001b[0m Trial 33 finished with value: 0.61494140625 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1100, 'learning_rate': 'invscaling', 'eta0': 0.471508240183626}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:20,383]\u001b[0m Trial 34 finished with value: 0.608984375 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1100, 'learning_rate': 'invscaling', 'eta0': 0.35978810226007163}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:20,897]\u001b[0m Trial 35 finished with value: 0.60576171875 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1200, 'learning_rate': 'invscaling', 'eta0': 0.08285981739134778}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:21,858]\u001b[0m Trial 36 finished with value: 0.58662109375 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1100, 'learning_rate': 'constant', 'eta0': 0.033134030858414286}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:22,430]\u001b[0m Trial 37 finished with value: 0.608203125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1300, 'learning_rate': 'invscaling', 'eta0': 0.010131379397009409}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:23,018]\u001b[0m Trial 38 finished with value: 0.58681640625 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1200, 'learning_rate': 'optimal'}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:24,228]\u001b[0m Trial 39 finished with value: 0.5865234375 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'adaptive', 'eta0': 0.4528263518609185}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:26,226]\u001b[0m Trial 40 finished with value: 0.5955078125 and parameters: {'loss': 'modified_huber', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'invscaling', 'eta0': 0.24064257051560986}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:27,255]\u001b[0m Trial 41 finished with value: 0.61103515625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.5719023773959443}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:28,300]\u001b[0m Trial 42 finished with value: 0.61142578125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.5950076279949595}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:28,962]\u001b[0m Trial 43 finished with value: 0.6083984375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1100, 'learning_rate': 'invscaling', 'eta0': 0.11450436731971456}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:29,325]\u001b[0m Trial 44 finished with value: 0.58154296875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.00429487948030984}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:30,126]\u001b[0m Trial 45 finished with value: 0.587890625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1100, 'learning_rate': 'optimal'}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:30,883]\u001b[0m Trial 46 finished with value: 0.56806640625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1200, 'learning_rate': 'constant', 'eta0': 0.4444060179205349}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:31,544]\u001b[0m Trial 47 finished with value: 0.61162109375 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.24884579165537357}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:32,362]\u001b[0m Trial 48 finished with value: 0.61298828125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.03237845413031152}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:33,116]\u001b[0m Trial 49 finished with value: 0.6115234375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.02463729293513936}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:33,461]\u001b[0m Trial 50 finished with value: 0.5828125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.0010280419274334416}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:33,957]\u001b[0m Trial 51 finished with value: 0.60126953125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.005340933703061799}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:34,690]\u001b[0m Trial 52 finished with value: 0.6125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.022616149483003428}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:35,508]\u001b[0m Trial 53 finished with value: 0.61298828125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.031978616416936737}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:36,264]\u001b[0m Trial 54 finished with value: 0.61025390625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.02317489922942797}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:36,896]\u001b[0m Trial 55 finished with value: 0.60859375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1800, 'learning_rate': 'invscaling', 'eta0': 0.013395714326762629}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:37,782]\u001b[0m Trial 56 finished with value: 0.61162109375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.04380935005093117}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:38,263]\u001b[0m Trial 57 finished with value: 0.5580078125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1800, 'learning_rate': 'optimal'}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:39,174]\u001b[0m Trial 58 finished with value: 0.6107421875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.04108633641496616}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:40,256]\u001b[0m Trial 59 finished with value: 0.60888671875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'invscaling', 'eta0': 0.08188374981242762}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:41,060]\u001b[0m Trial 60 finished with value: 0.56083984375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'adaptive', 'eta0': 0.05147921762981533}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:41,740]\u001b[0m Trial 61 finished with value: 0.61025390625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.01824260117571759}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:42,322]\u001b[0m Trial 62 finished with value: 0.6076171875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.009425663512805682}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:42,753]\u001b[0m Trial 63 finished with value: 0.5931640625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1400, 'learning_rate': 'invscaling', 'eta0': 0.0026593901466136793}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:43,577]\u001b[0m Trial 64 finished with value: 0.6109375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1900, 'learning_rate': 'invscaling', 'eta0': 0.03325902263311006}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:44,725]\u001b[0m Trial 65 finished with value: 0.6076171875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.09968610448946601}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:45,475]\u001b[0m Trial 66 finished with value: 0.609765625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.020863836274342587}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:46,472]\u001b[0m Trial 67 finished with value: 0.61142578125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'invscaling', 'eta0': 0.05830673997428262}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:47,033]\u001b[0m Trial 68 finished with value: 0.60849609375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1400, 'learning_rate': 'invscaling', 'eta0': 0.00820196865459587}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:47,860]\u001b[0m Trial 69 finished with value: 0.5630859375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'constant', 'eta0': 0.012764467728911846}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:48,136]\u001b[0m Trial 70 finished with value: 0.55302734375 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.11710922841063878}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:49,025]\u001b[0m Trial 71 finished with value: 0.61279296875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.040061687620110184}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:49,889]\u001b[0m Trial 72 finished with value: 0.61162109375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.038496879678621046}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:50,765]\u001b[0m Trial 73 finished with value: 0.61064453125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.03941062311077502}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:51,750]\u001b[0m Trial 74 finished with value: 0.6111328125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1400, 'learning_rate': 'invscaling', 'eta0': 0.05679279952073873}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:52,964]\u001b[0m Trial 75 finished with value: 0.60517578125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.13435250303802274}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:54,024]\u001b[0m Trial 76 finished with value: 0.60830078125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.07110065056923784}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:55,335]\u001b[0m Trial 77 finished with value: 0.5958984375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'invscaling', 'eta0': 0.2278419948530681}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:56,011]\u001b[0m Trial 78 finished with value: 0.6078125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.016197162708631304}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:56,821]\u001b[0m Trial 79 finished with value: 0.61064453125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.030163426670363445}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:57,257]\u001b[0m Trial 80 finished with value: 0.5494140625 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'max_iter': 1400, 'learning_rate': 'adaptive', 'eta0': 0.0058200890480856185}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:57,989]\u001b[0m Trial 81 finished with value: 0.61025390625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.021726110455509238}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:58,926]\u001b[0m Trial 82 finished with value: 0.6123046875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.04843815027382412}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:04:59,811]\u001b[0m Trial 83 finished with value: 0.6119140625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.04074728543348407}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:00,696]\u001b[0m Trial 84 finished with value: 0.61259765625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.03920402991774313}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:01,516]\u001b[0m Trial 85 finished with value: 0.61083984375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.031838425547909534}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:01,983]\u001b[0m Trial 86 finished with value: 0.560546875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'optimal'}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:03,030]\u001b[0m Trial 87 finished with value: 0.6109375 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1400, 'learning_rate': 'invscaling', 'eta0': 0.07085856666876042}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:03,959]\u001b[0m Trial 88 finished with value: 0.6107421875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'invscaling', 'eta0': 0.04789559597870621}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:04,220]\u001b[0m Trial 89 finished with value: 0.57890625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.00019548854171292358}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:05,029]\u001b[0m Trial 90 finished with value: 0.56328125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1400, 'learning_rate': 'constant', 'eta0': 0.012539316473089205}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:06,131]\u001b[0m Trial 91 finished with value: 0.6078125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.08641867369253657}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:07,417]\u001b[0m Trial 92 finished with value: 0.60087890625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.17282077562887513}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:08,311]\u001b[0m Trial 93 finished with value: 0.61181640625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.03882640619329763}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:09,085]\u001b[0m Trial 94 finished with value: 0.61142578125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1400, 'learning_rate': 'invscaling', 'eta0': 0.026448027376190078}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:10,403]\u001b[0m Trial 95 finished with value: 0.5939453125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.2678627895156201}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:11,094]\u001b[0m Trial 96 finished with value: 0.6095703125 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1300, 'learning_rate': 'invscaling', 'eta0': 0.017368666395975726}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:12,688]\u001b[0m Trial 97 finished with value: 0.60693359375 and parameters: {'loss': 'modified_huber', 'penalty': 'l1', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.14673533698626864}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:13,711]\u001b[0m Trial 98 finished with value: 0.6103515625 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.06355659518495507}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:05:13,987]\u001b[0m Trial 99 finished with value: 0.55078125 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'invscaling', 'eta0': 0.100244616984852}. Best is trial 33 with value: 0.61494140625.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsaLssDI2G42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1e04ea-6aed-44e1-b40b-8313d3c955af"
      },
      "source": [
        "# Best trial\n",
        "\n",
        "sgd_trial = study.best_trial\n",
        "\n",
        "sgd_best = SGDClassifier(**sgd_trial.params)\n",
        "sgd_best.fit(count_train, y_train)\n",
        "(sgd_best.predict(count_train) == y_train).mean(), (sgd_best.predict(count_valid) == y_valid).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.72353515625, 0.6253894080996885)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAMHsx6DHUp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95051b8-1df7-4514-86b6-0682bb070242"
      },
      "source": [
        "# sgd evaluation\n",
        "\n",
        "evaluate_on_data(SGDClassifier(**sgd_trial.params), count_train, y_train, \"SGD Count\")\n",
        "evaluate_on_data(SGDClassifier(**sgd_trial.params), count_valid, y_valid, \"SGD Count\", \"valid\")\n",
        "evaluate_on_data(SGDClassifier(**sgd_trial.params), count_test, y_test, \"SGD Count\", \"test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|            SGD Count(train)           |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|72.197266|77.053276|71.825695|83.10153|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|            SGD Count(valid)           |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|90.88785|91.262136|91.058122|91.467066|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|            SGD Count(test)            |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|90.292028|91.739422|88.129032|95.658263|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzYEsVDU16QV"
      },
      "source": [
        "## Creating Count Vectorizer piplines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlDhfp801-qt"
      },
      "source": [
        "# logreg pipeline\n",
        "\n",
        "logreg_pipeline = Pipeline([\n",
        "     ('count_vec', CountVectorizer()),\n",
        "     ('logreg', LogisticRegression(**logreg_trial.params))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6mRcTO7ipb"
      },
      "source": [
        "# nb pipeline\n",
        "\n",
        "nb_pipeline = Pipeline([\n",
        "      ('count_vec', CountVectorizer()),\n",
        "      ('nb', MultinomialNB(**nb_trial.params))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2nmYqPe7i1X"
      },
      "source": [
        "# svc pipeline\n",
        "\n",
        "svc_pipeline = Pipeline([\n",
        "      ('count_vec', CountVectorizer()),\n",
        "      ('svc', SVC(**svc_trial.params, probability=True))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcgggcGh1-tb"
      },
      "source": [
        "# rf pipeline\n",
        "\n",
        "rf_pipeline = Pipeline([\n",
        "      ('count_vec', CountVectorizer()),\n",
        "      ('rf', RandomForestClassifier(**rf_trial.params))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flPxe_5G1-vU"
      },
      "source": [
        "# sgd pipeline\n",
        "\n",
        "sgd_pipeline = Pipeline([\n",
        "      ('count_vec', CountVectorizer()),\n",
        "      ('pa', SGDClassifier(**sgd_trial.params))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6pMp4Z815S4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de47b97-a9f0-4155-c0f8-fb3f939f485f"
      },
      "source": [
        "# Ensemble of the above classifiers\n",
        "\n",
        "list_clfs = [('logreg_pipeline', logreg_pipeline), ('nb_pipeline', nb_pipeline), ('svc_pipeline', svc_pipeline), ('rf_pipeline', rf_pipeline), ('sgd_pipeline', sgd_pipeline)]\n",
        "\n",
        "count_detector = VotingClassifier(estimators=list_clfs, voting='soft', n_jobs=-1)\n",
        "count_detector.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('logreg_pipeline',\n",
              "                              Pipeline(memory=None,\n",
              "                                       steps=[('count_vec',\n",
              "                                               CountVectorizer(analyzer='word',\n",
              "                                                               binary=False,\n",
              "                                                               decode_error='strict',\n",
              "                                                               dtype=<class 'numpy.int64'>,\n",
              "                                                               encoding='utf-8',\n",
              "                                                               input='content',\n",
              "                                                               lowercase=True,\n",
              "                                                               max_df=1.0,\n",
              "                                                               max_features=None,\n",
              "                                                               min_df=1,\n",
              "                                                               ngram_range=(1,\n",
              "                                                                            1),\n",
              "                                                               preprocessor=None,\n",
              "                                                               stop_words=None,\n",
              "                                                               strip_accents=None,\n",
              "                                                               token_patt...\n",
              "                                                             early_stopping=False,\n",
              "                                                             epsilon=0.1,\n",
              "                                                             eta0=0.471508240183626,\n",
              "                                                             fit_intercept=True,\n",
              "                                                             l1_ratio=0.15,\n",
              "                                                             learning_rate='invscaling',\n",
              "                                                             loss='log',\n",
              "                                                             max_iter=1100,\n",
              "                                                             n_iter_no_change=5,\n",
              "                                                             n_jobs=None,\n",
              "                                                             penalty='l2',\n",
              "                                                             power_t=0.5,\n",
              "                                                             random_state=None,\n",
              "                                                             shuffle=True,\n",
              "                                                             tol=0.001,\n",
              "                                                             validation_fraction=0.1,\n",
              "                                                             verbose=0,\n",
              "                                                             warm_start=False))],\n",
              "                                       verbose=False))],\n",
              "                 flatten_transform=True, n_jobs=-1, voting='soft',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n9D--CqaT-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161d8bb5-442b-4d7d-cb54-9105ed576401"
      },
      "source": [
        "# Prediction from voting classifier\n",
        "\n",
        "print((count_detector.predict(X_valid) == y_valid).mean())\n",
        "evaluate_on_data(count_detector, X_train, y_train, \"Ensemble Classifier Count\")\n",
        "evaluate_on_data(count_detector, X_valid, y_valid, \"Ensemble Classifier Count\", \"valid\")\n",
        "evaluate_on_data(count_detector, X_test, y_test, \"Ensemble Classifier Count\", \"test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5763239875389408\n",
            "+---------------------------------------+\n",
            "|    Ensemble Classifier Count(train)   |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|90.888672|92.34053|87.478613|97.774687|\n",
            "+---------------------------------------+\n",
            "\n",
            "[[3683  805]\n",
            " [ 128 5624]]\n",
            "+---------------------------------------+\n",
            "|    Ensemble Classifier Count(valid)   |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|97.507788|97.608371|97.462687|97.754491|\n",
            "+---------------------------------------+\n",
            "\n",
            "[[599  17]\n",
            " [ 15 653]]\n",
            "+---------------------------------------+\n",
            "|    Ensemble Classifier Count(test)    |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|97.632202|97.942387|95.967742|100.0|\n",
            "+---------------------------------------+\n",
            "\n",
            "[[523  30]\n",
            " [  0 714]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nvavz-ddE0c"
      },
      "source": [
        "## Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPIVW1O6HN4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfb6a61-b028-40b0-c719-1b02c667cf06"
      },
      "source": [
        "# Defining tfidf vector\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit(X_train, y_train)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2HetZGSR7pS"
      },
      "source": [
        "# Getting vectors of train and valid\n",
        "\n",
        "tfidf_train = tfidf.transform(X_train)\n",
        "tfidf_valid = tfidf.transform(X_valid)\n",
        "tfidf_test = tfidf.transform(X_test)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CYwLxQXql5_"
      },
      "source": [
        "## Hyperparameter tuning (Tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbY-VsEsqs1Z"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pty-pQEuDJFN"
      },
      "source": [
        "# Parameter grid\n",
        "\n",
        "def objective(trial):\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
        "    C = trial.suggest_loguniform('C', 10e-6, 1)\n",
        "\n",
        "    params = {'penalty': penalty, 'C': C}\n",
        "\n",
        "    clf = LogisticRegression(**params)\n",
        "\n",
        "    return cross_val_score(clf, tfidf_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvd_HGReDJFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fdd469a-eef5-48e4-f07d-5f5654a27c9e"
      },
      "source": [
        "# Logistic Regression fitting\n",
        "\n",
        "study = optuna.create_study(study_name='tfidf_logreg', direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 02:36:59,940]\u001b[0m A new study created in memory with name: tfidf_logreg\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 02:37:00,040]\u001b[0m Trial 0 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 02:37:00,131]\u001b[0m Trial 1 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 02:37:00,224]\u001b[0m Trial 2 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:00,881]\u001b[0m Trial 3 finished with value: 0.56318359375 and parameters: {'penalty': 'l2', 'C': 0.032013841632899935}. Best is trial 3 with value: 0.56318359375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:01,373]\u001b[0m Trial 4 finished with value: 0.56171875 and parameters: {'penalty': 'l2', 'C': 2.3505942936436858e-05}. Best is trial 3 with value: 0.56318359375.\u001b[0m\n",
            "\u001b[33m[W 2021-05-10 02:37:01,471]\u001b[0m Trial 5 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:01,998]\u001b[0m Trial 6 finished with value: 0.56171875 and parameters: {'penalty': 'l2', 'C': 0.005880592095153536}. Best is trial 3 with value: 0.56318359375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:02,775]\u001b[0m Trial 7 finished with value: 0.57568359375 and parameters: {'penalty': 'l2', 'C': 0.061557736632856706}. Best is trial 7 with value: 0.57568359375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:03,239]\u001b[0m Trial 8 finished with value: 0.56171875 and parameters: {'penalty': 'l2', 'C': 0.00456532951107739}. Best is trial 7 with value: 0.57568359375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:05,071]\u001b[0m Trial 9 finished with value: 0.6115234375 and parameters: {'penalty': 'l2', 'C': 0.6884368269354376}. Best is trial 9 with value: 0.6115234375.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXlbRbyTDJFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d896e3-5317-4fec-f23a-44b5e9ced8b9"
      },
      "source": [
        "# Best trial\n",
        "\n",
        "logreg_trial = study.best_trial\n",
        "\n",
        "best_logreg = LogisticRegression(**logreg_trial.params)\n",
        "best_logreg.fit(tfidf_train, y_train)\n",
        "(best_logreg.predict(tfidf_train) == y_train).mean(), (best_logreg.predict(tfidf_valid) == y_valid).mean()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7693359375, 0.6238317757009346)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im-M0l_v9otS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460370b0-5695-4828-d8c2-d300c52a6f84"
      },
      "source": [
        "# logreg evaluation\n",
        "\n",
        "evaluate_on_data(LogisticRegression(**logreg_trial.params), tfidf_train, y_train, \"Logistic Regression Tfidf\")\n",
        "evaluate_on_data(LogisticRegression(**logreg_trial.params), tfidf_valid, y_valid, \"Logistic Regression Tfidf\", \"valid\")\n",
        "evaluate_on_data(LogisticRegression(**logreg_trial.params), tfidf_test, y_test, \"Logistic Regression Tfidf\", \"test\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|    Logistic Regression Tfidf(train)   |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|76.933594|81.319203|74.593732|89.377608|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|    Logistic Regression Tfidf(valid)   |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|90.264798|90.909091|88.401697|93.562874|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|    Logistic Regression Tfidf(test)    |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|85.003946|88.139825|79.504505|98.879552|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w24TgJckEDpu"
      },
      "source": [
        "### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z2qTK4nDWjy"
      },
      "source": [
        "# Parametr grid\n",
        "\n",
        "def objective(trial):\n",
        "    alpha = trial.suggest_int('alpha', 1.0, 8.0)\n",
        "\n",
        "    clf = MultinomialNB(alpha=alpha)\n",
        "\n",
        "    return cross_val_score(clf, tfidf_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAzsIo7dDWj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093f91e9-e0a4-41a0-cdeb-50608277df16"
      },
      "source": [
        "# Multinomail navie bayes fitting\n",
        "\n",
        "study = optuna.create_study(study_name='tfidf_nb', direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 02:37:21,513]\u001b[0m A new study created in memory with name: tfidf_nb\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:21,870]\u001b[0m Trial 0 finished with value: 0.56943359375 and parameters: {'alpha': 8}. Best is trial 0 with value: 0.56943359375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:22,229]\u001b[0m Trial 1 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 1 with value: 0.59765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:22,579]\u001b[0m Trial 2 finished with value: 0.5736328125 and parameters: {'alpha': 6}. Best is trial 1 with value: 0.59765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:22,930]\u001b[0m Trial 3 finished with value: 0.5736328125 and parameters: {'alpha': 6}. Best is trial 1 with value: 0.59765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:23,280]\u001b[0m Trial 4 finished with value: 0.5908203125 and parameters: {'alpha': 3}. Best is trial 1 with value: 0.59765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:23,626]\u001b[0m Trial 5 finished with value: 0.5765625 and parameters: {'alpha': 5}. Best is trial 1 with value: 0.59765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:23,984]\u001b[0m Trial 6 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 1 with value: 0.59765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:24,345]\u001b[0m Trial 7 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:24,684]\u001b[0m Trial 8 finished with value: 0.5765625 and parameters: {'alpha': 5}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:25,038]\u001b[0m Trial 9 finished with value: 0.56943359375 and parameters: {'alpha': 8}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:25,390]\u001b[0m Trial 10 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:25,732]\u001b[0m Trial 11 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:26,080]\u001b[0m Trial 12 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:26,426]\u001b[0m Trial 13 finished with value: 0.5908203125 and parameters: {'alpha': 3}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:26,769]\u001b[0m Trial 14 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:27,128]\u001b[0m Trial 15 finished with value: 0.5908203125 and parameters: {'alpha': 3}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:27,488]\u001b[0m Trial 16 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:27,824]\u001b[0m Trial 17 finished with value: 0.5828125 and parameters: {'alpha': 4}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:28,174]\u001b[0m Trial 18 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:28,526]\u001b[0m Trial 19 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:28,872]\u001b[0m Trial 20 finished with value: 0.5828125 and parameters: {'alpha': 4}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:29,209]\u001b[0m Trial 21 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:29,559]\u001b[0m Trial 22 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:29,897]\u001b[0m Trial 23 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:30,241]\u001b[0m Trial 24 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:30,594]\u001b[0m Trial 25 finished with value: 0.5908203125 and parameters: {'alpha': 3}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:30,940]\u001b[0m Trial 26 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:31,282]\u001b[0m Trial 27 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:31,640]\u001b[0m Trial 28 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:31,978]\u001b[0m Trial 29 finished with value: 0.56943359375 and parameters: {'alpha': 8}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:32,322]\u001b[0m Trial 30 finished with value: 0.5908203125 and parameters: {'alpha': 3}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:32,681]\u001b[0m Trial 31 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:33,017]\u001b[0m Trial 32 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:33,365]\u001b[0m Trial 33 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:33,714]\u001b[0m Trial 34 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:34,057]\u001b[0m Trial 35 finished with value: 0.57109375 and parameters: {'alpha': 7}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:34,408]\u001b[0m Trial 36 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:34,779]\u001b[0m Trial 37 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:35,118]\u001b[0m Trial 38 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:35,465]\u001b[0m Trial 39 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:35,816]\u001b[0m Trial 40 finished with value: 0.5828125 and parameters: {'alpha': 4}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:36,157]\u001b[0m Trial 41 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:36,518]\u001b[0m Trial 42 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:36,863]\u001b[0m Trial 43 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:37,202]\u001b[0m Trial 44 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:37,547]\u001b[0m Trial 45 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:37,891]\u001b[0m Trial 46 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:38,235]\u001b[0m Trial 47 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:38,594]\u001b[0m Trial 48 finished with value: 0.5736328125 and parameters: {'alpha': 6}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:38,938]\u001b[0m Trial 49 finished with value: 0.5908203125 and parameters: {'alpha': 3}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:39,287]\u001b[0m Trial 50 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:39,644]\u001b[0m Trial 51 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:39,981]\u001b[0m Trial 52 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:40,338]\u001b[0m Trial 53 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:40,690]\u001b[0m Trial 54 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:41,038]\u001b[0m Trial 55 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:41,379]\u001b[0m Trial 56 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:41,729]\u001b[0m Trial 57 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:42,067]\u001b[0m Trial 58 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:42,411]\u001b[0m Trial 59 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:42,768]\u001b[0m Trial 60 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:43,106]\u001b[0m Trial 61 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:43,454]\u001b[0m Trial 62 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:43,808]\u001b[0m Trial 63 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:44,148]\u001b[0m Trial 64 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:44,504]\u001b[0m Trial 65 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:44,851]\u001b[0m Trial 66 finished with value: 0.5765625 and parameters: {'alpha': 5}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:45,217]\u001b[0m Trial 67 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:45,563]\u001b[0m Trial 68 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:45,913]\u001b[0m Trial 69 finished with value: 0.5908203125 and parameters: {'alpha': 3}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:46,260]\u001b[0m Trial 70 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:46,620]\u001b[0m Trial 71 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:46,968]\u001b[0m Trial 72 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:47,322]\u001b[0m Trial 73 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:47,663]\u001b[0m Trial 74 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:48,017]\u001b[0m Trial 75 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:48,361]\u001b[0m Trial 76 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:48,708]\u001b[0m Trial 77 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:49,061]\u001b[0m Trial 78 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:49,413]\u001b[0m Trial 79 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:49,754]\u001b[0m Trial 80 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:50,095]\u001b[0m Trial 81 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:50,434]\u001b[0m Trial 82 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:50,781]\u001b[0m Trial 83 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:51,124]\u001b[0m Trial 84 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:51,468]\u001b[0m Trial 85 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:51,808]\u001b[0m Trial 86 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:52,164]\u001b[0m Trial 87 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:52,499]\u001b[0m Trial 88 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:52,844]\u001b[0m Trial 89 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:53,192]\u001b[0m Trial 90 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:53,533]\u001b[0m Trial 91 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:53,879]\u001b[0m Trial 92 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:54,220]\u001b[0m Trial 93 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:54,568]\u001b[0m Trial 94 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:54,916]\u001b[0m Trial 95 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:55,259]\u001b[0m Trial 96 finished with value: 0.59765625 and parameters: {'alpha': 2}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:55,596]\u001b[0m Trial 97 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:55,964]\u001b[0m Trial 98 finished with value: 0.60712890625 and parameters: {'alpha': 1}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:37:56,318]\u001b[0m Trial 99 finished with value: 0.5736328125 and parameters: {'alpha': 6}. Best is trial 7 with value: 0.60712890625.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOHegKsGDWj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad957f6-1a82-48b5-8138-b897330b188c"
      },
      "source": [
        "# Best params\n",
        "\n",
        "nb_trial = study.best_trial\n",
        "\n",
        "nb_best = MultinomialNB(**nb_trial.params)\n",
        "nb_best.fit(tfidf_train, y_train)\n",
        "(nb_best.predict(tfidf_train) == y_train).mean(), (nb_best.predict(tfidf_valid) == y_valid).mean()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.78232421875, 0.5965732087227414)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twxF8OydF72t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca547baf-7531-4c41-9005-f2415699b9aa"
      },
      "source": [
        "# nb evaluation\n",
        "\n",
        "evaluate_on_data(MultinomialNB(**nb_trial.params), tfidf_train, y_train, \"Multinomial NB Tfidf\")\n",
        "evaluate_on_data(MultinomialNB(**nb_trial.params), tfidf_valid, y_valid, \"Multinomial NB Tfidf\", \"valid\")\n",
        "evaluate_on_data(MultinomialNB(**nb_trial.params), tfidf_test, y_test, \"Multinomial NB Tfidf\", \"test\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|      Multinomial NB Tfidf(train)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|78.232422|83.203979|73.427317|95.984006|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|      Multinomial NB Tfidf(valid)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|92.367601|92.95977|89.364641|96.856287|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|       Multinomial NB Tfidf(test)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|83.583268|87.270502|77.5|99.859944|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPHQO7RlEI7Y"
      },
      "source": [
        "### Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7_C46F3D1r0"
      },
      "source": [
        "# Parameter grid\n",
        "\n",
        "def objective(trial):\n",
        "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "    if kernel is 'poly':\n",
        "        degree = trial.suggest_int('degree', 1, 4)\n",
        "        gamma = trial.suggest_categorical('gamma', ['scale','auto'])\n",
        "        clf = SVC(kernel=kernel, degree=degree, gamma=gamma)\n",
        "\n",
        "    if kernel in ['rbf', 'sigmoid']:\n",
        "        gamma = trial.suggest_categorical('gamma', ['scale','auto'])\n",
        "        clf = SVC(kernel=kernel, gamma=gamma)\n",
        "\n",
        "    clf = SVC(kernel=kernel)\n",
        "\n",
        "    return cross_val_score(clf, tfidf_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Z3i8suD1r2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eebdf46-49d8-4509-dfc3-01fe309b729f"
      },
      "source": [
        "# Support Vector Machines fitting\n",
        "\n",
        "study = optuna.create_study(study_name='tfidf_svc', direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 02:37:56,480]\u001b[0m A new study created in memory with name: tfidf_svc\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning:\n",
            "\n",
            "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "\n",
            "\u001b[32m[I 2021-05-10 02:40:31,925]\u001b[0m Trial 0 finished with value: 0.58330078125 and parameters: {'kernel': 'poly', 'degree': 3, 'gamma': 'auto'}. Best is trial 0 with value: 0.58330078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:43:09,134]\u001b[0m Trial 1 finished with value: 0.58330078125 and parameters: {'kernel': 'poly', 'degree': 3, 'gamma': 'scale'}. Best is trial 0 with value: 0.58330078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:45:46,395]\u001b[0m Trial 2 finished with value: 0.58330078125 and parameters: {'kernel': 'poly', 'degree': 3, 'gamma': 'scale'}. Best is trial 0 with value: 0.58330078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:47:13,908]\u001b[0m Trial 3 finished with value: 0.60615234375 and parameters: {'kernel': 'linear'}. Best is trial 3 with value: 0.60615234375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:48:44,601]\u001b[0m Trial 4 finished with value: 0.6072265625 and parameters: {'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.6072265625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:50:16,170]\u001b[0m Trial 5 finished with value: 0.6072265625 and parameters: {'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.6072265625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:52:14,928]\u001b[0m Trial 6 finished with value: 0.6130859375 and parameters: {'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:54:53,735]\u001b[0m Trial 7 finished with value: 0.58330078125 and parameters: {'kernel': 'poly', 'degree': 1, 'gamma': 'scale'}. Best is trial 6 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:56:24,417]\u001b[0m Trial 8 finished with value: 0.60615234375 and parameters: {'kernel': 'linear'}. Best is trial 6 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 02:57:56,093]\u001b[0m Trial 9 finished with value: 0.6072265625 and parameters: {'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 6 with value: 0.6130859375.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eE44G30D1r3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d15dead-50b2-485d-d0bb-03c227054b31"
      },
      "source": [
        "# Best params\n",
        "\n",
        "svc_trial = study.best_trial\n",
        "\n",
        "svc_best = SVC(**svc_trial.params)\n",
        "svc_best.fit(tfidf_train, y_train)\n",
        "(svc_best.predict(tfidf_train) == y_train).mean(), (svc_best.predict(tfidf_valid) == y_valid).mean()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.96396484375, 0.6105919003115264)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlJIr686Fz1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b45c9a74-c5a1-4181-e6df-8f38ebf0a4d7"
      },
      "source": [
        "# svc evaluation\n",
        "\n",
        "evaluate_on_data(SVC(**svc_trial.params, probability=True), tfidf_train, y_train, \"SVC Count\")\n",
        "evaluate_on_data(SVC(**svc_trial.params, probability=True), tfidf_valid, y_valid, \"SVC Count\", \"valid\")\n",
        "evaluate_on_data(SVC(**svc_trial.params, probability=True), tfidf_test, y_test, \"SVC Count\", \"test\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|            SVC Count(train)           |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|96.396484|96.864111|94.746467|99.078581|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|            SVC Count(valid)           |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|99.454829|99.47644|99.402093|99.550898|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|            SVC Count(test)            |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|99.52644|99.58159|99.166667|100.0|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nJLCmBjEM64"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKt0-0_pD__b"
      },
      "source": [
        "# Parameters grid\n",
        "\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 1000, 100)\n",
        "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
        "    max_depth = trial.suggest_categorical('max_depth', [4, 5, 6, None])\n",
        "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2', None])\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, max_features=max_features)\n",
        "\n",
        "    return cross_val_score(clf, tfidf_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFWDYBE0D__d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5456dcff-ff09-4ce0-9ebc-e51a6a52a71a"
      },
      "source": [
        "# Random Forest fitting\n",
        "\n",
        "study = optuna.create_study(study_name='tfidf_rf', direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 04:15:57,295]\u001b[0m A new study created in memory with name: tfidf_rf\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 04:26:32,537]\u001b[0m Trial 0 finished with value: 0.6140625 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2'}. Best is trial 0 with value: 0.6140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 04:27:27,616]\u001b[0m Trial 1 finished with value: 0.56171875 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 04:32:53,649]\u001b[0m Trial 2 finished with value: 0.61181640625 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto'}. Best is trial 0 with value: 0.6140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 04:33:21,878]\u001b[0m Trial 3 finished with value: 0.56171875 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2'}. Best is trial 0 with value: 0.6140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 04:34:07,340]\u001b[0m Trial 4 finished with value: 0.56171875 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto'}. Best is trial 0 with value: 0.6140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 04:45:49,540]\u001b[0m Trial 5 finished with value: 0.56884765625 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 4, 'max_features': None}. Best is trial 0 with value: 0.6140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 04:46:33,624]\u001b[0m Trial 6 finished with value: 0.56171875 and parameters: {'n_estimators': 700, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:03:29,441]\u001b[0m Trial 7 finished with value: 0.57138671875 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6, 'max_features': None}. Best is trial 0 with value: 0.6140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:03:38,244]\u001b[0m Trial 8 finished with value: 0.56171875 and parameters: {'n_estimators': 300, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2'}. Best is trial 0 with value: 0.6140625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:54:06,129]\u001b[0m Trial 9 finished with value: 0.60283203125 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'max_depth': None, 'max_features': None}. Best is trial 0 with value: 0.6140625.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIVDrPkED__e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42ba0f9-6ec3-4f1c-e698-b78cc9e32026"
      },
      "source": [
        "# Best params\n",
        "\n",
        "rf_trial = study.best_trial\n",
        "\n",
        "rf_best = RandomForestClassifier(**rf_trial.params)\n",
        "rf_best.fit(tfidf_train, y_train)\n",
        "(rf_best.predict(tfidf_train) == y_train).mean(), (rf_best.predict(tfidf_valid) == y_valid).mean()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.999609375, 0.5973520249221184)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofW-hf-1Fsh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b4cb55-a006-4422-b6cf-ae09a8a440e2"
      },
      "source": [
        "# rf evaluation\n",
        "\n",
        "evaluate_on_data(RandomForestClassifier(**rf_trial.params), tfidf_train, y_train, \"Random Forest Count\")\n",
        "evaluate_on_data(RandomForestClassifier(**rf_trial.params), tfidf_valid, y_valid, \"Random Forest Count\", \"valid\")\n",
        "evaluate_on_data(RandomForestClassifier(**rf_trial.params), tfidf_test, y_test, \"Random Forest Count\", \"test\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|       Random Forest Count(train)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|99.960938|99.965229|99.965229|99.965229|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|       Random Forest Count(valid)      |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|100.0|100.0|100.0|100.0|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|       Random Forest Count(test)       |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|100.0|100.0|100.0|100.0|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQ3boiqEQaC"
      },
      "source": [
        "### Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXcUso03ERZf"
      },
      "source": [
        "# Parameters grid\n",
        "\n",
        "def objective(trial):\n",
        "    loss = trial.suggest_categorical('loss', ['log', 'modified_huber', 'perceptron'])\n",
        "    penalty = trial.suggest_categorical('penalty', ['l2', 'l1', 'elasticnet'])\n",
        "    max_iter = trial.suggest_int('max_iter', 1000, 2000, 100)\n",
        "    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'optimal', 'invscaling', 'adaptive'])\n",
        "    if learning_rate is not 'optimal':\n",
        "        eta0 = trial.suggest_loguniform('eta0', 10e-6, 1)\n",
        "    else:\n",
        "        eta0 = 0\n",
        "\n",
        "    clf = SGDClassifier(loss=loss, penalty=penalty, learning_rate=learning_rate, eta0=eta0, max_iter=max_iter)\n",
        "\n",
        "    return cross_val_score(clf, count_train, y_train, cv=10, n_jobs=-1).mean()"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E7hrb-sEqU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef595100-a3c2-403b-9c8e-43c5f84e8cbb"
      },
      "source": [
        "# SGD fitting\n",
        "\n",
        "study = optuna.create_study(study_name='tfidf_sgd', direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-10 05:57:29,623]\u001b[0m A new study created in memory with name: tfidf_sgd\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:30,451]\u001b[0m Trial 0 finished with value: 0.548046875 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'max_iter': 1700, 'learning_rate': 'optimal'}. Best is trial 0 with value: 0.548046875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:32,889]\u001b[0m Trial 1 finished with value: 0.58662109375 and parameters: {'loss': 'modified_huber', 'penalty': 'l1', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.000812443266322384}. Best is trial 1 with value: 0.58662109375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:33,356]\u001b[0m Trial 2 finished with value: 0.557421875 and parameters: {'loss': 'modified_huber', 'penalty': 'l2', 'max_iter': 1100, 'learning_rate': 'optimal'}. Best is trial 1 with value: 0.58662109375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:33,655]\u001b[0m Trial 3 finished with value: 0.5787109375 and parameters: {'loss': 'modified_huber', 'penalty': 'l1', 'max_iter': 1300, 'learning_rate': 'invscaling', 'eta0': 0.00019597762348780065}. Best is trial 1 with value: 0.58662109375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:34,225]\u001b[0m Trial 4 finished with value: 0.55263671875 and parameters: {'loss': 'perceptron', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'optimal'}. Best is trial 1 with value: 0.58662109375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:34,827]\u001b[0m Trial 5 finished with value: 0.57880859375 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1400, 'learning_rate': 'adaptive', 'eta0': 2.6686534340633604e-05}. Best is trial 1 with value: 0.58662109375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:35,309]\u001b[0m Trial 6 finished with value: 0.5541015625 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'adaptive', 'eta0': 0.02516145831264626}. Best is trial 1 with value: 0.58662109375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:36,071]\u001b[0m Trial 7 finished with value: 0.58740234375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'optimal'}. Best is trial 7 with value: 0.58740234375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:38,665]\u001b[0m Trial 8 finished with value: 0.6029296875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'adaptive', 'eta0': 0.004744947942468407}. Best is trial 8 with value: 0.6029296875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:39,298]\u001b[0m Trial 9 finished with value: 0.60146484375 and parameters: {'loss': 'modified_huber', 'penalty': 'l1', 'max_iter': 1300, 'learning_rate': 'invscaling', 'eta0': 0.005409628160310571}. Best is trial 8 with value: 0.6029296875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:41,127]\u001b[0m Trial 10 finished with value: 0.58818359375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'adaptive', 'eta0': 0.37468813932341644}. Best is trial 8 with value: 0.6029296875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:41,565]\u001b[0m Trial 11 finished with value: 0.58662109375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1200, 'learning_rate': 'invscaling', 'eta0': 0.012733230819683783}. Best is trial 8 with value: 0.6029296875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:42,250]\u001b[0m Trial 12 finished with value: 0.6021484375 and parameters: {'loss': 'modified_huber', 'penalty': 'l1', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.0069240801547126325}. Best is trial 8 with value: 0.6029296875.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:42,984]\u001b[0m Trial 13 finished with value: 0.60830078125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.1614624572390479}. Best is trial 13 with value: 0.60830078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:44,991]\u001b[0m Trial 14 finished with value: 0.5880859375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1500, 'learning_rate': 'adaptive', 'eta0': 0.9106497403897703}. Best is trial 13 with value: 0.60830078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:45,817]\u001b[0m Trial 15 finished with value: 0.58173828125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1900, 'learning_rate': 'constant', 'eta0': 0.13136152055288977}. Best is trial 13 with value: 0.60830078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:47,761]\u001b[0m Trial 16 finished with value: 0.59013671875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1500, 'learning_rate': 'adaptive', 'eta0': 0.09446463709785174}. Best is trial 13 with value: 0.60830078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:48,088]\u001b[0m Trial 17 finished with value: 0.578515625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.0005841926708300407}. Best is trial 13 with value: 0.60830078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:49,452]\u001b[0m Trial 18 finished with value: 0.59033203125 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1800, 'learning_rate': 'adaptive', 'eta0': 0.04858251197429324}. Best is trial 13 with value: 0.60830078125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:51,006]\u001b[0m Trial 19 finished with value: 0.611328125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0015962765860173312}. Best is trial 19 with value: 0.611328125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:51,515]\u001b[0m Trial 20 finished with value: 0.5896484375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1400, 'learning_rate': 'constant', 'eta0': 7.938216274629063e-05}. Best is trial 19 with value: 0.611328125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:52,986]\u001b[0m Trial 21 finished with value: 0.61259765625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0014091944342055815}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:54,267]\u001b[0m Trial 22 finished with value: 0.61181640625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0009680459841538021}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:55,755]\u001b[0m Trial 23 finished with value: 0.61240234375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0013876974387395213}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:56,489]\u001b[0m Trial 24 finished with value: 0.60458984375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0002719177014790251}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:58,133]\u001b[0m Trial 25 finished with value: 0.608984375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.001876448752059455}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:58,401]\u001b[0m Trial 26 finished with value: 0.552734375 and parameters: {'loss': 'perceptron', 'penalty': 'elasticnet', 'max_iter': 1400, 'learning_rate': 'constant', 'eta0': 7.164974508650068e-05}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:57:59,242]\u001b[0m Trial 27 finished with value: 0.6111328125 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0006757017551014328}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:00,948]\u001b[0m Trial 28 finished with value: 0.6107421875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1500, 'learning_rate': 'constant', 'eta0': 0.002221859500513703}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:01,226]\u001b[0m Trial 29 finished with value: 0.559765625 and parameters: {'loss': 'perceptron', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 1.0739735118236196e-05}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:01,972]\u001b[0m Trial 30 finished with value: 0.60283203125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0002553723707043765}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:03,517]\u001b[0m Trial 31 finished with value: 0.61103515625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0015363611682974545}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:04,811]\u001b[0m Trial 32 finished with value: 0.61240234375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.000997111482232338}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:05,791]\u001b[0m Trial 33 finished with value: 0.60830078125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1900, 'learning_rate': 'constant', 'eta0': 0.0005025537846241987}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:07,049]\u001b[0m Trial 34 finished with value: 0.61103515625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.0009002620518503515}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:08,679]\u001b[0m Trial 35 finished with value: 0.565625 and parameters: {'loss': 'modified_huber', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.010645668153799435}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:09,161]\u001b[0m Trial 36 finished with value: 0.59404296875 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.00011879355013322635}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:09,933]\u001b[0m Trial 37 finished with value: 0.55556640625 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'max_iter': 1500, 'learning_rate': 'optimal'}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:11,765]\u001b[0m Trial 38 finished with value: 0.60732421875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1400, 'learning_rate': 'constant', 'eta0': 0.0032635965017804116}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:13,100]\u001b[0m Trial 39 finished with value: 0.6119140625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1900, 'learning_rate': 'constant', 'eta0': 0.0009578656780025912}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:13,789]\u001b[0m Trial 40 finished with value: 0.56015625 and parameters: {'loss': 'modified_huber', 'penalty': 'elasticnet', 'max_iter': 1900, 'learning_rate': 'optimal'}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:15,187]\u001b[0m Trial 41 finished with value: 0.612109375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.001156927603638914}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:16,016]\u001b[0m Trial 42 finished with value: 0.60849609375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'constant', 'eta0': 0.00036434157870600826}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:17,408]\u001b[0m Trial 43 finished with value: 0.6123046875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.001153292532443798}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:19,280]\u001b[0m Trial 44 finished with value: 0.6076171875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.0033908184201628788}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:20,480]\u001b[0m Trial 45 finished with value: 0.59638671875 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.018886080396239884}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:21,114]\u001b[0m Trial 46 finished with value: 0.598046875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.00016279848006424248}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:22,998]\u001b[0m Trial 47 finished with value: 0.59765625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.00660901871908483}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:23,377]\u001b[0m Trial 48 finished with value: 0.5498046875 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'max_iter': 1800, 'learning_rate': 'optimal'}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:26,010]\u001b[0m Trial 49 finished with value: 0.57783203125 and parameters: {'loss': 'modified_huber', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'constant', 'eta0': 0.001315402619114376}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:27,073]\u001b[0m Trial 50 finished with value: 0.610546875 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1900, 'learning_rate': 'constant', 'eta0': 0.002950746146965518}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:28,021]\u001b[0m Trial 51 finished with value: 0.60830078125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1900, 'learning_rate': 'constant', 'eta0': 0.00046687830117072985}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:29,263]\u001b[0m Trial 52 finished with value: 0.61083984375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1900, 'learning_rate': 'constant', 'eta0': 0.0008456657353103867}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:30,698]\u001b[0m Trial 53 finished with value: 0.6119140625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0012009236109570534}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:32,613]\u001b[0m Trial 54 finished with value: 0.5998046875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.005200173205401366}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:34,335]\u001b[0m Trial 55 finished with value: 0.610546875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.0022080741112829004}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:35,157]\u001b[0m Trial 56 finished with value: 0.6072265625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0003419116913707682}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:35,549]\u001b[0m Trial 57 finished with value: 0.584375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.00967240129426045}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:38,122]\u001b[0m Trial 58 finished with value: 0.60546875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'adaptive', 'eta0': 0.0037085085498487136}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:39,269]\u001b[0m Trial 59 finished with value: 0.61181640625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.0007180954521943354}. Best is trial 21 with value: 0.61259765625.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:40,784]\u001b[0m Trial 60 finished with value: 0.6126953125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'constant', 'eta0': 0.001420266844492031}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:42,214]\u001b[0m Trial 61 finished with value: 0.61123046875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1900, 'learning_rate': 'constant', 'eta0': 0.0012002984728184203}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:43,909]\u001b[0m Trial 62 finished with value: 0.61103515625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0020584646580890736}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:45,394]\u001b[0m Trial 63 finished with value: 0.61181640625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0013539755592421646}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:46,390]\u001b[0m Trial 64 finished with value: 0.60810546875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1500, 'learning_rate': 'constant', 'eta0': 0.0005285152384908162}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:47,052]\u001b[0m Trial 65 finished with value: 0.59970703125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0001778417916532673}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:47,391]\u001b[0m Trial 66 finished with value: 0.577734375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'invscaling', 'eta0': 0.002584430866183314}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:48,784]\u001b[0m Trial 67 finished with value: 0.6009765625 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 2000, 'learning_rate': 'constant', 'eta0': 0.004456697425774264}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:50,071]\u001b[0m Trial 68 finished with value: 0.6119140625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'constant', 'eta0': 0.0009381903250563957}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:51,384]\u001b[0m Trial 69 finished with value: 0.608984375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1900, 'learning_rate': 'adaptive', 'eta0': 0.00037938711733054027}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:51,672]\u001b[0m Trial 70 finished with value: 0.55361328125 and parameters: {'loss': 'perceptron', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'constant', 'eta0': 0.0006537310440618388}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:53,107]\u001b[0m Trial 71 finished with value: 0.61220703125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0012304143181758717}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:54,725]\u001b[0m Trial 72 finished with value: 0.6107421875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0017330993672257486}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:56,172]\u001b[0m Trial 73 finished with value: 0.61123046875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0012208302309899151}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:56,891]\u001b[0m Trial 74 finished with value: 0.60302734375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1500, 'learning_rate': 'constant', 'eta0': 0.00024069570404788122}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:58:59,710]\u001b[0m Trial 75 finished with value: 0.5830078125 and parameters: {'loss': 'modified_huber', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.000745594476426006}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:00,509]\u001b[0m Trial 76 finished with value: 0.58505859375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'optimal'}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:01,492]\u001b[0m Trial 77 finished with value: 0.60966796875 and parameters: {'loss': 'log', 'penalty': 'l1', 'max_iter': 1900, 'learning_rate': 'constant', 'eta0': 0.0020062296249596582}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:02,450]\u001b[0m Trial 78 finished with value: 0.608203125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0004790265181354063}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:04,352]\u001b[0m Trial 79 finished with value: 0.59697265625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.007406061448725194}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:05,666]\u001b[0m Trial 80 finished with value: 0.61171875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.0009667727679342941}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:07,211]\u001b[0m Trial 81 finished with value: 0.612109375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0014904892614597332}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:08,848]\u001b[0m Trial 82 finished with value: 0.609765625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0018299855504043444}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:10,271]\u001b[0m Trial 83 finished with value: 0.61142578125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.001214173160171602}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:11,364]\u001b[0m Trial 84 finished with value: 0.61083984375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1500, 'learning_rate': 'constant', 'eta0': 0.0006452885288656758}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:13,210]\u001b[0m Trial 85 finished with value: 0.60791015625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1900, 'learning_rate': 'constant', 'eta0': 0.002910189341681286}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:15,104]\u001b[0m Trial 86 finished with value: 0.60419921875 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1800, 'learning_rate': 'constant', 'eta0': 0.004093983630811289}. Best is trial 60 with value: 0.6126953125.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:16,086]\u001b[0m Trial 87 finished with value: 0.6130859375 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0009679650423854973}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:17,281]\u001b[0m Trial 88 finished with value: 0.61015625 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.0016219499595665433}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:17,535]\u001b[0m Trial 89 finished with value: 0.553125 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'max_iter': 1600, 'learning_rate': 'invscaling', 'eta0': 0.002626985761182209}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:19,963]\u001b[0m Trial 90 finished with value: 0.58623046875 and parameters: {'loss': 'modified_huber', 'penalty': 'l1', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0009668169666136075}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:20,868]\u001b[0m Trial 91 finished with value: 0.61064453125 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0007781723328067792}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:22,001]\u001b[0m Trial 92 finished with value: 0.61142578125 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1700, 'learning_rate': 'constant', 'eta0': 0.0013990275762255768}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:22,619]\u001b[0m Trial 93 finished with value: 0.6072265625 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'constant', 'eta0': 0.00032062910005307526}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:23,542]\u001b[0m Trial 94 finished with value: 0.60830078125 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'constant', 'eta0': 0.00044800019452311793}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:24,881]\u001b[0m Trial 95 finished with value: 0.612890625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'constant', 'eta0': 0.001050594505068497}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:25,627]\u001b[0m Trial 96 finished with value: 0.58837890625 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1600, 'learning_rate': 'optimal'}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:27,331]\u001b[0m Trial 97 finished with value: 0.6109375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 2000, 'learning_rate': 'constant', 'eta0': 0.002300318430210967}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:28,877]\u001b[0m Trial 98 finished with value: 0.61083984375 and parameters: {'loss': 'log', 'penalty': 'elasticnet', 'max_iter': 1400, 'learning_rate': 'adaptive', 'eta0': 0.000594730904361722}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n",
            "\u001b[32m[I 2021-05-10 05:59:30,094]\u001b[0m Trial 99 finished with value: 0.6103515625 and parameters: {'loss': 'log', 'penalty': 'l2', 'max_iter': 1500, 'learning_rate': 'constant', 'eta0': 0.001628920580816836}. Best is trial 87 with value: 0.6130859375.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg_v4BSvFm8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b3ac0f-5ed8-49c4-cb5e-4faafb150d2b"
      },
      "source": [
        "# sgd evaluation\n",
        "\n",
        "evaluate_on_data(SGDClassifier(**sgd_trial.params), tfidf_train, y_train, \"SGD Count\")\n",
        "evaluate_on_data(SGDClassifier(**sgd_trial.params), tfidf_valid, y_valid, \"SGD Count\", \"valid\")\n",
        "evaluate_on_data(SGDClassifier(**sgd_trial.params), tfidf_test, y_test, \"SGD Count\", \"test\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|            SGD Count(train)           |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|58.007812|72.569533|57.315599|98.887344|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|            SGD Count(valid)           |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|82.320872|84.31237|78.30552|91.317365|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|            SGD Count(test)            |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|63.456985|75.489677|60.680851|99.859944|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A74sVwxEque"
      },
      "source": [
        "## Creating Tfidf Vectorizer piplines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyXbocXOEqug"
      },
      "source": [
        "# logreg pipeline\n",
        "\n",
        "logreg_pipeline = Pipeline([\n",
        "     ('tfidf_vec', TfidfVectorizer()),\n",
        "     ('logreg', LogisticRegression(**logreg_trial.params))\n",
        "])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUv47keoEqui"
      },
      "source": [
        "# nb pipeline\n",
        "\n",
        "nb_pipeline = Pipeline([\n",
        "      ('tfidf_vec', TfidfVectorizer()),\n",
        "      ('nb', MultinomialNB(**nb_trial.params))\n",
        "])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdZJG4ZMEquj"
      },
      "source": [
        "# svc pipeline\n",
        "\n",
        "svc_pipeline = Pipeline([\n",
        "      ('tfidf_vec', TfidfVectorizer()),\n",
        "      ('svc', SVC(**svc_trial.params, probability=True))\n",
        "])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG8kNp8QEquj"
      },
      "source": [
        "# rf pipeline\n",
        "\n",
        "rf_pipeline = Pipeline([\n",
        "      ('tfidf_vec', TfidfVectorizer()),\n",
        "      ('rf', RandomForestClassifier(**rf_trial.params))\n",
        "])"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-3wreQYEquk"
      },
      "source": [
        "# sgd pipeline\n",
        "\n",
        "sgd_pipeline = Pipeline([\n",
        "      ('tfidf_vec', TfidfVectorizer()),\n",
        "      ('sgd', SGDClassifier(**sgd_trial.params))\n",
        "])"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3y-IDANEqul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e913b2e2-00a6-45cd-d52a-21321ac8c60f"
      },
      "source": [
        "# Ensemble of the above classifiers\n",
        "\n",
        "list_clfs = [('logreg_pipeline', logreg_pipeline), ('nb_pipeline', nb_pipeline), ('svc_pipeline', svc_pipeline), ('rf_pipeline', rf_pipeline), ('sgd_pipeline', sgd_pipeline)]\n",
        "\n",
        "tfidf_detector = VotingClassifier(estimators=list_clfs, voting='soft', n_jobs=-1)\n",
        "tfidf_detector.fit(X_train, y_train)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning:\n",
            "\n",
            "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('logreg_pipeline',\n",
              "                              Pipeline(memory=None,\n",
              "                                       steps=[('tfidf_vec',\n",
              "                                               TfidfVectorizer(analyzer='word',\n",
              "                                                               binary=False,\n",
              "                                                               decode_error='strict',\n",
              "                                                               dtype=<class 'numpy.float64'>,\n",
              "                                                               encoding='utf-8',\n",
              "                                                               input='content',\n",
              "                                                               lowercase=True,\n",
              "                                                               max_df=1.0,\n",
              "                                                               max_features=None,\n",
              "                                                               min_df=1,\n",
              "                                                               ngram_range=(1,\n",
              "                                                                            1),\n",
              "                                                               norm='l2',\n",
              "                                                               preprocessor=None,\n",
              "                                                               smooth_idf=True,\n",
              "                                                               stop_words=None,\n",
              "                                                               s...\n",
              "                                                             early_stopping=False,\n",
              "                                                             epsilon=0.1,\n",
              "                                                             eta0=0.471508240183626,\n",
              "                                                             fit_intercept=True,\n",
              "                                                             l1_ratio=0.15,\n",
              "                                                             learning_rate='invscaling',\n",
              "                                                             loss='log',\n",
              "                                                             max_iter=1100,\n",
              "                                                             n_iter_no_change=5,\n",
              "                                                             n_jobs=None,\n",
              "                                                             penalty='l2',\n",
              "                                                             power_t=0.5,\n",
              "                                                             random_state=None,\n",
              "                                                             shuffle=True,\n",
              "                                                             tol=0.001,\n",
              "                                                             validation_fraction=0.1,\n",
              "                                                             verbose=0,\n",
              "                                                             warm_start=False))],\n",
              "                                       verbose=False))],\n",
              "                 flatten_transform=True, n_jobs=-1, voting='soft',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX9ArypbEqum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd515f73-d0e2-458c-9cc2-86c522981297"
      },
      "source": [
        "# Prediction from voting classifier\n",
        "\n",
        "(tfidf_detector.predict(X_valid) == y_valid).mean()\n",
        "evaluate_on_data(tfidf_detector, X_train, y_train, \"Ensemble Classifier Tfidf\")\n",
        "evaluate_on_data(tfidf_detector, X_valid, y_valid, \"Ensemble Classifier Tfidf\", \"valid\")\n",
        "evaluate_on_data(tfidf_detector, X_test, y_test, \"Ensemble Classifier Tfidf\", \"test\")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning:\n",
            "\n",
            "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|    Ensemble Classifier Tfidf(train)   |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|94.472656|95.284905|91.474728|99.426287|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|    Ensemble Classifier Tfidf(valid)   |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|99.221184|99.251497|99.251497|99.251497|\n",
            "+---------------------------------------+\n",
            "\n",
            "+---------------------------------------+\n",
            "|    Ensemble Classifier Tfidf(test)    |\n",
            "+---------------------------------------+\n",
            "| Accuracy|    F1   |  Recall |Precision|\n",
            "+---------------------------------------+\n",
            "|98.342541|98.550725|97.142857|100.0|\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}